This project demonstrates the use of vector search for image retrieval. The goal was to experiment with searching images using text queries. 
To achieve this, the CLIP pre-trained model was used to embed image captions into numerical representations (vectors). 
These vectors were then stored in a vector store using FAISS, which enables efficient similarity search. The project can be executed using either Google Colab or Jupyter Notebook.
