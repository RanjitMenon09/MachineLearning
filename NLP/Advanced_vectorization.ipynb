{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1bcb0ed",
   "metadata": {},
   "source": [
    "## Advanced vectorization using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85edb9f",
   "metadata": {},
   "source": [
    "#### Use BeautifulSoup and extract some quotes and then use this for the vectoraztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c0f7468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.6.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (9.4.0)\n",
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.8.2.2.tar.gz (220 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (1.24.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (3.6.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ranjit09\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "  Running setup.py install for wordcloud: started\n",
      "  Running setup.py install for wordcloud: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: wordcloud is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for wordcloud did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [22 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\ranjit09\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-311\n",
      "  creating build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\color_from_image.py -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\tokenization.py -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\wordcloud.py -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\wordcloud_cli.py -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\_version.py -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\__init__.py -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\__main__.py -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\stopwords -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  copying wordcloud\\DroidSansMono.ttf -> build\\lib.win-amd64-cpython-311\\wordcloud\n",
      "  UPDATING build\\lib.win-amd64-cpython-311\\wordcloud/_version.py\n",
      "  set build\\lib.win-amd64-cpython-311\\wordcloud/_version.py to '1.8.2.2'\n",
      "  running build_ext\n",
      "  building 'wordcloud.query_integral_image' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "wordcloud\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "#install Libraries\n",
    "!pip install -U scikit-learn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1776cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text             author\n",
      "0  “The world as we have created it is a process ...    Albert Einstein\n",
      "1  “It is our choices, Harry, that show what we t...       J.K. Rowling\n",
      "2  “There are only two ways to live your life. On...    Albert Einstein\n",
      "3  “The person, be it gentleman or lady, who has ...        Jane Austen\n",
      "4  “Imperfection is beauty, madness is genius and...     Marilyn Monroe\n",
      "5  “Try not to become a man of success. Rather be...    Albert Einstein\n",
      "6  “It is better to be hated for what you are tha...         André Gide\n",
      "7  “I have not failed. I've just found 10,000 way...   Thomas A. Edison\n",
      "8  “A woman is like a tea bag; you never know how...  Eleanor Roosevelt\n",
      "9  “A day without sunshine is like, you know, nig...       Steve Martin\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a GET request to the website\n",
    "response = requests.get(\"https://quotes.toscrape.com/\")\n",
    "\n",
    "#print(response.content)\n",
    "# Parse the HTML content\n",
    "bs = BeautifulSoup(response.content)\n",
    "\n",
    "\n",
    "# Find all the quote elements on the page\n",
    "quote_text = bs.find_all(\"span\", {\"class\":\"text\"})\n",
    "quote_author = bs.find_all(\"small\", {\"class\":\"author\"})\n",
    "#print(quote_author)\n",
    "\n",
    "\n",
    "# Extract the text and author of each quote\n",
    "quotes = []\n",
    "for i, quote_element in enumerate(quote_elements):\n",
    "    #print(quote_element)\n",
    "    text = quote_text[i].text     \n",
    "    author = quote_author[i].text\n",
    "    quotes.append({\"text\": text,\"author\": author})\n",
    "    \n",
    "# Print the quotes\n",
    "#for quote in quotes:\n",
    "#   print(quote[\"text\"] + \" - \" + quote[\"author\"])\n",
    "\n",
    "# Create a dataframe from the quotes list\n",
    "df = pd.DataFrame(quotes)\n",
    "print(df)\n",
    "\n",
    "\n",
    "#save this to csv\n",
    "#df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0f9b8",
   "metadata": {},
   "source": [
    "### Represent the Text column from the above dataframe using BoW Vectorization, using scikit learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a5aeb025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>abilities</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>bag</th>\n",
       "      <th>beauty</th>\n",
       "      <th>better</th>\n",
       "      <th>boring</th>\n",
       "      <th>changed</th>\n",
       "      <th>changing</th>\n",
       "      <th>...</th>\n",
       "      <th>truly</th>\n",
       "      <th>try</th>\n",
       "      <th>value</th>\n",
       "      <th>ve</th>\n",
       "      <th>water</th>\n",
       "      <th>ways</th>\n",
       "      <th>woman</th>\n",
       "      <th>won</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  10  abilities  absolutely  bag  beauty  better  boring  changed  \\\n",
       "0    0   0          0           0    0       0       0       0        1   \n",
       "1    0   0          1           0    0       0       0       0        0   \n",
       "2    0   0          0           0    0       0       0       0        0   \n",
       "3    0   0          0           0    0       0       0       0        0   \n",
       "4    0   0          0           2    0       1       1       1        0   \n",
       "5    0   0          0           0    0       0       0       0        0   \n",
       "6    0   0          0           0    0       0       1       0        0   \n",
       "7    1   1          0           0    0       0       0       0        0   \n",
       "8    0   0          0           0    1       0       0       0        0   \n",
       "9    0   0          0           0    0       0       0       0        0   \n",
       "\n",
       "   changing  ...  truly  try  value  ve  water  ways  woman  won  work  world  \n",
       "0         1  ...      0    0      0   0      0     0      0    0     0      1  \n",
       "1         0  ...      1    0      0   0      0     0      0    0     0      0  \n",
       "2         0  ...      0    0      0   0      0     1      0    0     0      0  \n",
       "3         0  ...      0    0      0   0      0     0      0    0     0      0  \n",
       "4         0  ...      0    0      0   0      0     0      0    0     0      0  \n",
       "5         0  ...      0    1      1   0      0     0      0    0     0      0  \n",
       "6         0  ...      0    0      0   0      0     0      0    0     0      0  \n",
       "7         0  ...      0    0      0   1      0     1      0    1     1      0  \n",
       "8         0  ...      0    0      0   0      1     0      1    0     0      0  \n",
       "9         0  ...      0    0      0   0      0     0      0    0     0      0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create an instance of the CountVectorizer class\n",
    "#vectorizer = CountVectorizer(stop_words='english', max_df=0.5, min_df=2)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the vectorizer on the text column of the dataframe\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "#print(vectorizer.vocabulary_.keys())\n",
    "#print(X)\n",
    "\n",
    "bow_df = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "bow_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7370d",
   "metadata": {},
   "source": [
    "### Displaying wordCloud for the above Text generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d4837920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from wordcloud import WordCloud\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Concatenate all the text in the dataframe into a single string\n",
    "#text = \" \".join(review for review in df[\"text\"])\n",
    "\n",
    "# Create a word cloud object\n",
    "#wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "#plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45de831",
   "metadata": {},
   "source": [
    "### using above dataframe, we can also use n-gram vectorization using 2,2 bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "be6ad342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000 ways', '10 000', 'absolutely boring', 'absolutely ridiculous',\n",
       "       'and it', 'are far', 'are not', 'are only', 'are than',\n",
       "       'as though', 'as we', 'bag you', 'be absolutely', 'be changed',\n",
       "       'be hated', 'be intolerably', 'be it', 'be loved',\n",
       "       'beauty madness', 'become man', 'better to', 'cannot be',\n",
       "       'changed without', 'changing our', 'choices harry', 'created it',\n",
       "       'day without', 'everything is', 'failed ve', 'far more',\n",
       "       'for what', 'found 10', 'genius and', 'gentleman or', 'good novel',\n",
       "       'harry that', 'has not', 'hated for', 'have created', 'have not',\n",
       "       'hot water', 'how strong', 'imperfection is', 'in good', 'in hot',\n",
       "       'intolerably stupid', 'is as', 'is beauty', 'is better',\n",
       "       'is genius', 'is like', 'is miracle', 'is our', 'is process',\n",
       "       'is until', 'it better', 'it cannot', 'it gentleman', 'it in',\n",
       "       'it is', 'just found', 'know how', 'know night', 'lady who',\n",
       "       'life one', 'like tea', 'like you', 'live your', 'loved for',\n",
       "       'madness is', 'man of', 'miracle the', 'more than', 'must be',\n",
       "       'never know', 'not failed', 'not pleasure', 'not to', 'nothing is',\n",
       "       'novel must', 'of our', 'of success', 'of value', 'one is',\n",
       "       'only two', 'or lady', 'other is', 'our abilities', 'our choices',\n",
       "       'our thinking', 'person be', 'pleasure in', 'process of',\n",
       "       'rather become', 'ridiculous than', 'show what', 'strong it',\n",
       "       'success rather', 'sunshine is', 'tea bag', 'than absolutely',\n",
       "       'than our', 'than to', 'that show', 'that won', 'the other',\n",
       "       'the person', 'the world', 'there are', 'thinking it',\n",
       "       'though everything', 'though nothing', 'to be', 'to become',\n",
       "       'to live', 'truly are', 'try not', 'two ways', 'until it',\n",
       "       've just', 'ways that', 'ways to', 'we have', 'we truly',\n",
       "       'what we', 'what you', 'who has', 'without changing',\n",
       "       'without sunshine', 'woman is', 'won work', 'world as', 'you are',\n",
       "       'you know', 'you never', 'your life'], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Create instance of CountVectorizer class with ngram_range set to (2, 2)\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "# Fit the vectorizer on the text column of the dataframe\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "#print(vectorizer.vocabulary_.keys())\n",
    "#print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a647b6",
   "metadata": {},
   "source": [
    "### apply tf-idf vectorization on the above dataframe for text column\n",
    "#### tf-idf vecorization is used to reflect how important a word is in a document in a collection or corpus. It is a weighing factor in information retrieval and text mining. \n",
    "#### tf-idf will tokenize and remove the stopwords by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0f73df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 74, 'world': 94, 'as': 6, 'we': 87, 'have': 30, 'created': 17, 'it': 37, 'is': 36, 'process': 63, 'of': 55, 'our': 60, 'thinking': 76, 'cannot': 13, 'be': 8, 'changed': 14, 'without': 90, 'changing': 15, 'choices': 16, 'harry': 27, 'that': 73, 'show': 66, 'what': 88, 'truly': 79, 'are': 5, 'far': 21, 'more': 48, 'than': 72, 'abilities': 2, 'there': 75, 'only': 57, 'two': 81, 'ways': 86, 'to': 78, 'live': 43, 'your': 96, 'life': 41, 'one': 56, 'though': 77, 'nothing': 53, 'miracle': 47, 'other': 59, 'everything': 19, 'person': 61, 'gentleman': 25, 'or': 58, 'lady': 40, 'who': 89, 'has': 28, 'not': 52, 'pleasure': 62, 'in': 34, 'good': 26, 'novel': 54, 'must': 49, 'intolerably': 35, 'stupid': 68, 'imperfection': 33, 'beauty': 9, 'madness': 45, 'genius': 24, 'and': 4, 'better': 11, 'absolutely': 3, 'ridiculous': 65, 'boring': 12, 'try': 80, 'become': 10, 'man': 46, 'success': 69, 'rather': 64, 'value': 83, 'hated': 29, 'for': 22, 'you': 95, 'loved': 44, 'failed': 20, 've': 84, 'just': 38, 'found': 23, '10': 1, '000': 0, 'won': 92, 'work': 93, 'woman': 91, 'like': 42, 'tea': 71, 'bag': 7, 'never': 50, 'know': 39, 'how': 32, 'strong': 67, 'until': 82, 'hot': 31, 'water': 85, 'day': 18, 'sunshine': 70, 'night': 51}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['000', '10', 'abilities', 'absolutely', 'and', 'are', 'as', 'bag',\n",
       "       'be', 'beauty', 'become', 'better', 'boring', 'cannot', 'changed',\n",
       "       'changing', 'choices', 'created', 'day', 'everything', 'failed',\n",
       "       'far', 'for', 'found', 'genius', 'gentleman', 'good', 'harry',\n",
       "       'has', 'hated', 'have', 'hot', 'how', 'imperfection', 'in',\n",
       "       'intolerably', 'is', 'it', 'just', 'know', 'lady', 'life', 'like',\n",
       "       'live', 'loved', 'madness', 'man', 'miracle', 'more', 'must',\n",
       "       'never', 'night', 'not', 'nothing', 'novel', 'of', 'one', 'only',\n",
       "       'or', 'other', 'our', 'person', 'pleasure', 'process', 'rather',\n",
       "       'ridiculous', 'show', 'strong', 'stupid', 'success', 'sunshine',\n",
       "       'tea', 'than', 'that', 'the', 'there', 'thinking', 'though', 'to',\n",
       "       'truly', 'try', 'two', 'until', 'value', 've', 'water', 'ways',\n",
       "       'we', 'what', 'who', 'without', 'woman', 'won', 'work', 'world',\n",
       "       'you', 'your'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create an instance of the TfidfVectorizer class\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the text column of the dataframe\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "#show the words corresponding to the column\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "#output the features corresponding to the column\n",
    "vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95440006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
