{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2086ce6c",
   "metadata": {},
   "source": [
    "## <div align=center>Assignment 02</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d270415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53436b0d",
   "metadata": {},
   "source": [
    "The GridWorld class encapsulates a simplified gridworld environment for reinforcement learning. It defines a 3x4 grid with an  initialized agent. The grid contains associated rewards for each cell, where encountering the danger results in a penalty (-10) and reaching the goal yields a reward (+100). The agent can take actions such as 'UP,' 'DOWN,' 'LEFT,' or 'RIGHT' to move within the grid, with boundaries enforced to prevent moving outside. The class provides methods to check available actions, display the grid with agent, goal, and danger locations for debugging, retrieve rewards for specific locations, simulate agent movements, and check if the agent is in a terminal state (goal or danger). This class serves as a foundational component for developing reinforcement learning algorithms in a gridworld scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb56ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    #ref https://gist.github.com/luqmanjamilch/f7a92c7419bdc47fdf231e7acb3bc63b\n",
    "    ## Initialise starting data\n",
    "    def __init__(self):\n",
    "        # Set information about the gridworld\n",
    "        self.height = 3\n",
    "        self.width = 4\n",
    "        self.grid = np.zeros(( self.height, self.width)) - 1\n",
    "        \n",
    "        # Set random start location for the agent\n",
    "        self.current_location = ( 2, 2) #starting position\n",
    "        \n",
    "        # Set locations for the danger and the goal\n",
    "        self.danger_location = (1,2)\n",
    "        self.goal_location = (0,0)\n",
    "        self.terminal_states = [ self.danger_location, self.goal_location]\n",
    "        \n",
    "        # Set grid rewards for special cells\n",
    "        self.grid[ self.danger_location[0], self.danger_location[1]] = -10\n",
    "        self.grid[ self.goal_location[0], self.goal_location[1]] = 100\n",
    "        \n",
    "        # Set available actions\n",
    "        self.actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
    "    \n",
    "    \n",
    "    # Returns possible actions\n",
    "    def get_available_actions(self):       \n",
    "        return self.actions\n",
    "           \n",
    "     #Prints out current location of the agent on the grid, along with goal and danger locations (used for debugging)\n",
    "    def agent_on_map(self):        \n",
    "        grid = np.zeros((self.height, self.width))\n",
    "\n",
    "        # Mark agent's location\n",
    "        grid[self.current_location[0], self.current_location[1]] = 1\n",
    "\n",
    "        # Mark goal location\n",
    "        grid[self.goal_location[0], self.goal_location[1]] = 100\n",
    "\n",
    "        # Mark danger location\n",
    "        grid[self.danger_location[0], self.danger_location[1]] = -10\n",
    "\n",
    "        return grid\n",
    "    \n",
    "    #Returns the reward for an input position   \n",
    "    def get_reward(self, new_location):             \n",
    "        return self.grid[ new_location[0], new_location[1]]\n",
    "        \n",
    "    # Moves the agent in the specified direction. If agent is at a border, agent stays still\n",
    "    # but takes negative reward. Function returns the reward for the move.\n",
    "    def make_step(self, action):       \n",
    "        # Store previous location\n",
    "        last_location = self.current_location\n",
    "        \n",
    "        # UP\n",
    "        if action == 'UP':\n",
    "            # If agent is at the top, stay still, collect reward\n",
    "            if last_location[0] == 0:\n",
    "                reward = self.get_reward(last_location)\n",
    "            else:\n",
    "                self.current_location = ( self.current_location[0] - 1, self.current_location[1])\n",
    "                reward = self.get_reward(self.current_location)\n",
    "        \n",
    "        # DOWN\n",
    "        elif action == 'DOWN':\n",
    "            # If agent is at bottom, stay still, collect reward\n",
    "            if last_location[0] == self.height - 1:\n",
    "                reward = self.get_reward(last_location)\n",
    "            else:\n",
    "                self.current_location = ( self.current_location[0] + 1, self.current_location[1])\n",
    "                reward = self.get_reward(self.current_location)\n",
    "            \n",
    "        # LEFT\n",
    "        elif action == 'LEFT':\n",
    "            # If agent is at the left, stay still, collect reward\n",
    "            if last_location[1] == 0:\n",
    "                reward = self.get_reward(last_location)\n",
    "            else:\n",
    "                self.current_location = ( self.current_location[0], self.current_location[1] - 1)\n",
    "                reward = self.get_reward(self.current_location)\n",
    "\n",
    "        # RIGHT\n",
    "        elif action == 'RIGHT':\n",
    "            # If agent is at the right, stay still, collect reward\n",
    "            if last_location[1] == self.width - 1:\n",
    "                reward = self.get_reward(last_location)\n",
    "            else:\n",
    "                self.current_location = ( self.current_location[0], self.current_location[1] + 1)\n",
    "                reward = self.get_reward(self.current_location)\n",
    "                \n",
    "        return reward\n",
    "    \n",
    "    # Check if the agent is in a terminal state (goal or danger), if so return 'TERMINAL'\n",
    "    def check_state(self):              \n",
    "        if self.current_location in self.terminal_states:\n",
    "            return 'TERMINAL'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ba74c14",
   "metadata": {},
   "source": [
    "**Which algorithm you will go with and why?**\n",
    "\n",
    "For this Grid wold problem, Q-learning is chosen for its effectiveness in solving. Its model-free approach, suitability for defined state-action spaces, and exploration-exploitation balance make it ideal. The algorithm's stability, convergence properties, and adaptability contribute to learning optimal policies in dynamic environments.\n",
    "\n",
    "\n",
    "The **Q_Agent** class represents an agent in a reinforcement learning scenario, employing the Q-learning algorithm to learn optimal actions in a given environment. Initialized with parameters such as exploration rate (epsilon), learning rate (alpha), and discount factor (gamma), the agent maintains a Q-value table, where each grid space has associated Q-values for possible actions ('UP,' 'DOWN,' 'LEFT,' 'RIGHT'). \n",
    "\n",
    "The **choose_action** method decides the agent's next action based on the Q-values of the current location, with an exploration-exploitation trade-off controlled by the exploration rate. \n",
    "\n",
    "The **learn** method updates the Q-value table using the Q-learning formula, incorporating rewards and the maximum Q-value in the next state. Overall, this class enables an agent to interact with its environment, learn from experiences, and make decisions to maximize cumulative rewards through Q-learning.\n",
    "\n",
    "The **learn** method implement the following mathematical equitation.\n",
    "![Q learning Equation](image.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d41ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_Agent():\n",
    "    # Intialise\n",
    "    def __init__(self, environment, epsilon=0.05, alpha=0.1, gamma=1):\n",
    "        self.environment = environment\n",
    "        self.q_table = dict() # Store all Q-values in dictionary of dictionaries \n",
    "        for x in range(environment.height): # Loop through all possible grid spaces, create sub-dictionary for each\n",
    "            for y in range(environment.width):\n",
    "                self.q_table[(x,y)] = {'UP':0, 'DOWN':0, 'LEFT':0, 'RIGHT':0} # Populate sub-dictionary with zero values for possible moves\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    # Returns the optimal action from Q-Value table. If multiple optimal actions, chooses random choice. Will make an exploratory random action dependent on epsilon.\n",
    "    def choose_action(self, available_actions):        \n",
    "        if np.random.uniform(0,1) < self.epsilon:\n",
    "            action = available_actions[np.random.randint(0, len(available_actions))]\n",
    "        else:\n",
    "            q_values_of_state = self.q_table[self.environment.current_location]            \n",
    "            maxValue = max(q_values_of_state.values())\n",
    "            action = np.random.choice([k for k, v in q_values_of_state.items() if v == maxValue])\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    # Updates the Q-value table using Q-learning\n",
    "    def learn(self, old_state, reward, new_state, action):        \n",
    "        q_values_of_state = self.q_table[new_state]\n",
    "        max_q_value_in_new_state = max(q_values_of_state.values())\n",
    "        current_q_value = self.q_table[old_state][action]\n",
    "        \n",
    "        self.q_table[old_state][action] = (1 - self.alpha) * current_q_value + self.alpha * (reward + self.gamma * max_q_value_in_new_state)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96890b",
   "metadata": {},
   "source": [
    "The **play** function simulates the interaction between a reinforcement learning agent and an environment over multiple trials. It takes as input the environment and agent instances, the number of trials, the maximum number of steps per episode, and a flag indicating whether the agent should learn from its experiences. During each trial, the agent selects actions based on its current policy, and the environment responds with rewards and new states. If learning is enabled, the agent updates its Q-values using the Q-learning algorithm. The function records the cumulative rewards obtained in each trial and returns a performance log, providing insights into the agent's learning progress and overall effectiveness in the given environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2627f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The play function runs iterations and updates Q-values if desired.\n",
    "def play(environment, agent, trials=500, max_steps_per_episode=1000, learn=False):   \n",
    "    reward_per_episode = [] # Initialise performance log\n",
    "    \n",
    "    for trial in range(trials): # Run trials\n",
    "        cumulative_reward = 0 # Initialise values of each game\n",
    "        step = 0\n",
    "        game_over = False\n",
    "        while step < max_steps_per_episode and game_over != True: # Run until max steps or until game is finished\n",
    "            old_state = environment.current_location\n",
    "            action = agent.choose_action(environment.actions) \n",
    "            reward = environment.make_step(action)\n",
    "            new_state = environment.current_location\n",
    "            \n",
    "            if learn == True: # Update Q-values if learning is specified\n",
    "                agent.learn(old_state, reward, new_state, action)\n",
    "                \n",
    "            cumulative_reward += reward\n",
    "            step += 1\n",
    "            \n",
    "            if environment.check_state() == 'TERMINAL': # If game is in terminal state, game over and start next trial\n",
    "                environment.__init__()\n",
    "                game_over = True     \n",
    "                \n",
    "        reward_per_episode.append(cumulative_reward) # Append reward for current trial to performance log\n",
    "        \n",
    "    return reward_per_episode # Return performance log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92129c",
   "metadata": {},
   "source": [
    "The provided code initializes an environment (GridWorld) and an agent (Q_Agent). The GridWorld represents a grid-based environment with specific characteristics,The Q_Agent is an agent designed for Q-learning, which interacts with the environment to learn optimal actions through a Q-value table. \n",
    "\n",
    "It prints the output to show the steps it get negative or positive reward based on the action it take\n",
    "\n",
    "To answer the question **what are the states in the layout ?**\n",
    "\n",
    "\n",
    "In the provided code, the states in the layout correspond to different positions on the grid within the GridWorld environment. Each state is represented by a tuple (x, y), where 'x' and 'y' are the coordinates of the agent on the grid. The agent can be in any position within the grid, and these positions constitute the states of the environment. The states exclude any terminal states where the agent reaches either the goal or the danger, as these states conclude the episode. \n",
    "\n",
    "To answer the question **What are the actions for the robot ?**\n",
    "\n",
    "In the given code, the agent has four possible actions:\n",
    "\n",
    "*Move UP*\n",
    "\n",
    "*Move DOWN*\n",
    "\n",
    "*Move LEFT*\n",
    "\n",
    "*Move RIGHT*\n",
    "\n",
    "These actions represent the possible directions in which the agent can move within the grid in the GridWorld environment. The agent can choose one of these actions at each step to navigate through the grid and interact with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47555223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available_actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
      "------------------------------------------\n",
      "Current position of the agent = (2, 2)\n",
      "[[100.   0.   0.   0.]\n",
      " [  0.   0. -10.   0.]\n",
      " [  0.   0.   1.   0.]]\n",
      "Randomly chosen action = DOWN\n",
      "Reward obtained = -1.0\n",
      "------------------------------------------\n",
      "Current position of the agent = (2, 2)\n",
      "[[100.   0.   0.   0.]\n",
      " [  0.   0. -10.   0.]\n",
      " [  0.   0.   1.   0.]]\n",
      "Randomly chosen action = DOWN\n",
      "Reward obtained = -1.0\n",
      "------------------------------------------\n",
      "Current position of the agent = (2, 2)\n",
      "[[100.   0.   0.   0.]\n",
      " [  0.   0. -10.   0.]\n",
      " [  0.   0.   1.   0.]]\n",
      "Randomly chosen action = RIGHT\n",
      "Reward obtained = -1.0\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld()\n",
    "agent =  Q_Agent(env)\n",
    "\n",
    "available_actions = env.get_available_actions()\n",
    "print(\"Available_actions =\", available_actions)\n",
    "print('------------------------------------------')\n",
    "print(\"Current position of the agent =\", env.current_location)\n",
    "print(env.agent_on_map())\n",
    "chosen_action = agent.choose_action(available_actions)\n",
    "print(\"Randomly chosen action =\", chosen_action)\n",
    "reward = env.make_step(chosen_action)\n",
    "print(\"Reward obtained =\", reward)\n",
    "print('------------------------------------------')\n",
    "print(\"Current position of the agent =\", env.current_location)\n",
    "print(env.agent_on_map())\n",
    "chosen_action = agent.choose_action(available_actions)\n",
    "print(\"Randomly chosen action =\", chosen_action)\n",
    "reward = env.make_step(chosen_action)\n",
    "print(\"Reward obtained =\", reward)\n",
    "print('------------------------------------------')\n",
    "print(\"Current position of the agent =\", env.current_location)\n",
    "print(env.agent_on_map())\n",
    "chosen_action = agent.choose_action(available_actions)\n",
    "print(\"Randomly chosen action =\", chosen_action)\n",
    "reward = env.make_step(chosen_action)\n",
    "print(\"Reward obtained =\", reward)\n",
    "print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12fb9f",
   "metadata": {},
   "source": [
    "In the below code snippet, an instance of the GridWorld environment and a Q-learning agent (Q_Agent) are created. The agent chooses an action, makes a step in the environment, and receives a reward. This process is repeated multiple times for the 500 trials we configured above, the rewards so obtained are printed for each iteration.\n",
    "\n",
    "To answer the question **How would you design the reward?**\n",
    "\n",
    "Rewards are determined based on the agent's actions and the current state of the environment. The rewards are predefined for certain states: stepping on the danger location results in a reward of -10, reaching the goal location yields a reward of 100, and all other non-terminal states provide a constant reward of -10. The Q-learning algorithm uses these rewards to update its Q-values during the learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03bd299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "environment = GridWorld()\n",
    "agentQ =  Q_Agent(environment)\n",
    "\n",
    "# Note the learn=True argument!\n",
    "reward_per_episode = play(environment, agentQ, trials=500, learn=True)\n",
    "\n",
    "# Simple learning curve\n",
    "plt.plot(reward_per_episode)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7863512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
